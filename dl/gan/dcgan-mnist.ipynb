{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install tensorflow==2.0.0-alpha0\n!pip install tensorflow-datasets\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting tensorflow==2.0.0-alpha0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/f99185d39131b8333afcfe1dcdb0629c2ffc4ecfb0e4c14ca210d620e56c/tensorflow-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (79.9MB)\n\u001b[K    100% |████████████████████████████████| 79.9MB 702kB/s eta 0:00:01    55% |█████████████████▉              | 44.6MB 52.0MB/s eta 0:00:01    72% |███████████████████████▎        | 58.2MB 45.1MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.12.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.19.0)\nCollecting google-pasta>=0.1.2 (from tensorflow==2.0.0-alpha0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/96/adbd4eafe72ce9b5ca6f168fbf109386e1b601f7c59926a11e9d7b7a5b44/google_pasta-0.1.4-py3-none-any.whl (51kB)\n\u001b[K    100% |████████████████████████████████| 61kB 24.0MB/s ta 0:00:01\n\u001b[?25hCollecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow==2.0.0-alpha0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n\u001b[K    100% |████████████████████████████████| 3.0MB 11.0MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.7.1)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (3.7.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.1.0)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.0.9)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.7.0)\nRequirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.16.2)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (1.0.7)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.31.1)\nCollecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow==2.0.0-alpha0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n\u001b[K    100% |████████████████████████████████| 419kB 35.9MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.0.0-alpha0) (0.2.2)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (0.14.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow==2.0.0-alpha0) (3.0.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==2.0.0-alpha0) (39.1.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-alpha0) (2.9.0)\nInstalling collected packages: google-pasta, tb-nightly, tf-estimator-nightly, tensorflow\n  Found existing installation: tensorflow 1.12.0\n    Uninstalling tensorflow-1.12.0:\n      Successfully uninstalled tensorflow-1.12.0\nSuccessfully installed google-pasta-0.1.4 tb-nightly-1.14.0a20190301 tensorflow-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\nCollecting tensorflow-datasets\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/b8/457ad44e8748fbe5021b4ca7e7d589b5852881bbb11bca4d947952a13558/tensorflow_datasets-1.0.1-py3-none-any.whl (400kB)\n\u001b[K    100% |████████████████████████████████| 409kB 12.2MB/s ta 0:00:01\n\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow-datasets) (3.7.0)\nCollecting promise (from tensorflow-datasets)\n  Downloading https://files.pythonhosted.org/packages/5a/81/221d09d90176fd90aed4b530e31b8fedf207385767c06d1d46c550c5e418/promise-2.2.1.tar.gz\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.6/site-packages (from tensorflow-datasets) (1.1.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.6/site-packages (from tensorflow-datasets) (1.10.11)\nRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from tensorflow-datasets) (0.17.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from tensorflow-datasets) (1.12.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from tensorflow-datasets) (4.31.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from tensorflow-datasets) (2.21.0)\nCollecting tensorflow-metadata (from tensorflow-datasets)\n  Downloading https://files.pythonhosted.org/packages/08/b7/3fc74574aa9aff44491cce996711dd6094653c20d9e2800be4efb054e0da/tensorflow_metadata-0.13.0-py3-none-any.whl\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.6/site-packages (from tensorflow-datasets) (0.7.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-datasets) (39.1.0)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->tensorflow-datasets) (2.6)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->tensorflow-datasets) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->tensorflow-datasets) (2019.3.9)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->tensorflow-datasets) (1.22)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.6/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.5.8)\nBuilding wheels for collected packages: promise\n  Building wheel for promise (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/92/84/9f/75e2235effae0e1c5a5c0626a503e532bbffcb7e79e672b606\nSuccessfully built promise\nInstalling collected packages: promise, tensorflow-metadata, tensorflow-datasets\nSuccessfully installed promise-2.2.1 tensorflow-datasets-1.0.1 tensorflow-metadata-0.13.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b4a7d288ff04677a4550b60c1ce53a8a248bc47"
      },
      "cell_type": "code",
      "source": "!git clone https://furiousavocados19:password1234@bitbucket.org/furiousavocados19/dcgan-mnist-models.git\n!mv dcgan-mnist-models checkpoints",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Cloning into 'dcgan-mnist-models'...\nremote: Counting objects: 57, done.\u001b[K\nremote: Compressing objects: 100% (57/57), done.\u001b[K\nremote: Total 57 (delta 26), reused 0 (delta 0)\u001b[K\nUnpacking objects: 100% (57/57), done.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94f350edf9727899cdb5129d9e5a3e6e61309514"
      },
      "cell_type": "code",
      "source": "BATCH_SIZE = 256\ndef normalize_image(example):\n    example['image'] = (tf.cast(example['image'], tf.float32) - 127.5) / 127.5 \n    return example\nmnist_train = tfds.load(name=\"mnist\", split=\"train\")\nmnist_train = mnist_train.shuffle(1024).batch(BATCH_SIZE)\nmnist_train = mnist_train.map(normalize_image)\n",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Dl Completed...: 0 url [00:00, ? url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nDl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nDl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nDl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nDl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nExtraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[A",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "\u001b[1mDownloading / extracting dataset mnist (11.06 MiB) to /tmp/tensorflow_datasets/mnist/1.0.0...\u001b[0m\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\nDl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n\nDl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\nDl Size...:   0%|          | 0/9 [00:00<?, ? MiB/s]\u001b[A\n\nDl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\nDl Size...:   0%|          | 0/9 [00:00<?, ? MiB/s]\u001b[A\n\nDl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.32 url/s]\nDl Size...:   0%|          | 0/9 [00:00<?, ? MiB/s]\u001b[A\n\nDl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.32 url/s]\nDl Size...:   0%|          | 0/9 [00:00<?, ? MiB/s]\u001b[A\n\nDl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.32 url/s]]\u001b[A\u001b[A\nDl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n\nExtraction completed...:   0%|          | 0/1 [00:00<?, ? file/s]\u001b[A\u001b[A\n\nDl Completed...:  25%|██▌       | 1/4 [00:00<00:00,  4.32 url/s]1 file/s]\u001b[A\u001b[A\nDl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n\nDl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.32 url/s]1 file/s]\u001b[A\u001b[A\nDl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n\nDl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.32 url/s]1 file/s]\u001b[A\u001b[A\nDl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n\nDl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.32 url/s]1 file/s]\u001b[A\u001b[A\nDl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n\nExtraction completed...: 100%|██████████| 2/2 [00:00<00:00,  4.21 file/s]\u001b[A\u001b[A\nDl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.32 url/s]\nDl Size...:  10%|█         | 1/10 [00:00<00:06,  1.42 MiB/s]\u001b[A\n\nDl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.32 url/s]1 file/s]\u001b[A\u001b[A\nDl Size...:  20%|██        | 2/10 [00:00<00:05,  1.42 MiB/s]\u001b[A\n\nDl Completed...:  50%|█████     | 2/4 [00:00<00:00,  4.32 url/s]1 file/s]\u001b[A\u001b[A\nDl Size...:  30%|███       | 3/10 [00:00<00:04,  1.42 MiB/s]\u001b[A\n\nDl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.04 url/s]1 file/s]\u001b[A\u001b[A\nDl Size...:  30%|███       | 3/10 [00:00<00:04,  1.42 MiB/s]\u001b[A\n\nDl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.04 url/s]1 file/s]\u001b[A\u001b[A\nDl Size...:  30%|███       | 3/10 [00:00<00:04,  1.42 MiB/s]\u001b[A\n\nExtraction completed...:  67%|██████▋   | 2/3 [00:00<00:00,  4.21 file/s]\u001b[A\u001b[A\nDl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.04 url/s]\nDl Size...:  40%|████      | 4/10 [00:00<00:03,  1.96 MiB/s]\u001b[A\n\nExtraction completed...:  67%|██████▋   | 2/3 [00:00<00:00,  4.21 file/s]\u001b[A\u001b[A\n\nDl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.04 url/s]7 file/s]\u001b[A\u001b[A\nDl Size...:  40%|████      | 4/10 [00:00<00:03,  1.96 MiB/s]\u001b[A\n\nDl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.04 url/s]7 file/s]\u001b[A\u001b[A\nDl Size...:  50%|█████     | 5/10 [00:00<00:02,  1.96 MiB/s]\u001b[A\n\nDl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.04 url/s]7 file/s]\u001b[A\u001b[A\nDl Size...:  60%|██████    | 6/10 [00:00<00:02,  1.96 MiB/s]\u001b[A\n\nDl Completed...:  75%|███████▌  | 3/4 [00:00<00:00,  4.04 url/s]7 file/s]\u001b[A\u001b[A\nDl Size...:  70%|███████   | 7/10 [00:00<00:01,  1.96 MiB/s]\u001b[A\n\nExtraction completed...: 100%|██████████| 3/3 [00:00<00:00,  3.77 file/s]\u001b[A\u001b[A\nDl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.04 url/s]\nDl Size...:  80%|████████  | 8/10 [00:01<00:00,  2.73 MiB/s]\u001b[A\n\nDl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.04 url/s]7 file/s]\u001b[A\u001b[A\nDl Size...:  90%|█████████ | 9/10 [00:01<00:00,  2.73 MiB/s]\u001b[A\n\nDl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  4.04 url/s]7 file/s]\u001b[A\u001b[A\nDl Size...: 100%|██████████| 10/10 [00:01<00:00,  2.73 MiB/s]\u001b[A\n\nDl Completed...: 100%|██████████| 4/4 [00:01<00:00,  3.82 url/s]7 file/s]\u001b[A\u001b[A\nDl Size...: 100%|██████████| 10/10 [00:01<00:00,  2.73 MiB/s]\u001b[A\n\nDl Completed...: 100%|██████████| 4/4 [00:01<00:00,  3.82 url/s]7 file/s]\u001b[A\u001b[A\nDl Size...: 100%|██████████| 10/10 [00:01<00:00,  2.73 MiB/s]\u001b[A\n\nExtraction completed...:  75%|███████▌  | 3/4 [00:01<00:00,  3.77 file/s]\u001b[A\u001b[A\n\nDl Completed...: 100%|██████████| 4/4 [00:01<00:00,  3.82 url/s]5 file/s]\u001b[A\u001b[A\nDl Size...: 100%|██████████| 10/10 [00:01<00:00,  2.73 MiB/s]\u001b[A\n\nExtraction completed...: 100%|██████████| 4/4 [00:01<00:00,  2.85 file/s]\u001b[A\u001b[A\nDl Size...: 100%|██████████| 10/10 [00:01<00:00,  6.82 MiB/s]\u001b[A\n29 examples [00:00, 289.32 examples/s]",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "\n\n\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "60000 examples [00:15, 3882.43 examples/s]\nShuffling...:   0%|          | 0/10 [00:00<?, ? shard/s]WARNING: Logging before flag parsing goes to stderr.\nW0317 03:39:01.513777 139886596937088 deprecation.py:323] From /opt/conda/lib/python3.6/site-packages/tensorflow_datasets/core/file_format_adapter.py:249: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse eager execution and: \n`tf.data.TFRecordDataset(path)`\n\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 264638.77 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nWriting...: 100%|██████████| 6000/6000 [00:00<00:00, 252638.48 examples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 284372.45 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nShuffling...:  20%|██        | 2/10 [00:00<00:00, 17.79 shard/s]xamples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 319067.67 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nWriting...: 100%|██████████| 6000/6000 [00:00<00:00, 217635.31 examples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 339922.52 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nShuffling...:  40%|████      | 4/10 [00:00<00:00, 18.21 shard/s]xamples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 318663.64 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nWriting...: 100%|██████████| 6000/6000 [00:00<00:00, 217368.38 examples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 342713.89 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nShuffling...:  60%|██████    | 6/10 [00:00<00:00, 18.50 shard/s]xamples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 325114.64 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nWriting...: 100%|██████████| 6000/6000 [00:00<00:00, 216758.03 examples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 309569.38 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nShuffling...:  80%|████████  | 8/10 [00:00<00:00, 18.60 shard/s]xamples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 329206.01 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nWriting...: 100%|██████████| 6000/6000 [00:00<00:00, 210442.98 examples/s]\u001b[A\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 6000 examples [00:00, 319067.67 examples/s]\u001b[A\nWriting...:   0%|          | 0/6000 [00:00<?, ? examples/s]\u001b[A\nShuffling...: 100%|██████████| 10/10 [00:00<00:00, 18.73 shard/s]amples/s]\u001b[A\n10000 examples [00:02, 3915.90 examples/s]\nShuffling...:   0%|          | 0/1 [00:00<?, ? shard/s]\nReading...: 0 examples [00:00, ? examples/s]\u001b[A\nReading...: 10000 examples [00:00, 380335.69 examples/s]\u001b[A\nWriting...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\nShuffling...: 100%|██████████| 1/1 [00:00<00:00, 12.69 shard/s]4 examples/s]\u001b[A\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def create_generator():\n    m= tf.keras.models.Sequential()\n    m.add(tf.keras.layers.Dense(4 * 4 * 256, use_bias=False, input_shape=(100,)))\n    m.add(tf.keras.layers.BatchNormalization())\n    m.add(tf.keras.layers.ReLU())\n\n    m.add(tf.keras.layers.Reshape((4, 4, 256)))\n    m.add(tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(1, 1), padding='valid', use_bias=False))\n\n    assert m.output_shape == (None, 5, 5, 128)\n    m.add(tf.keras.layers.BatchNormalization())\n    m.add(tf.keras.layers.ReLU())\n\n    m.add(tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='valid', use_bias=False))\n    assert m.output_shape == (None, 13, 13, 32)\n    m.add(tf.keras.layers.BatchNormalization())\n    m.add(tf.keras.layers.ReLU())\n\n    m.add(tf.keras.layers.Conv2DTranspose(1, (4, 4), strides=(2, 2), padding='valid', use_bias=False, activation=\"tanh\"))\n    assert m.output_shape == (None, 28, 28, 1)\n    \n    return m",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a74e5147b3185915692cfbc2cdf0b2d2ab42b11b"
      },
      "cell_type": "code",
      "source": "def create_discriminator():\n    m = tf.keras.models.Sequential()\n    m.add(tf.keras.layers.BatchNormalization(input_shape=(28, 28, 1)))\n    m.add(tf.keras.layers.LeakyReLU())\n\n    m.add(tf.keras.layers.Conv2D(\n        32, (3, 3),\n        strides=(1, 1),\n        padding=\"valid\"\n    ))\n    m.add(tf.keras.layers.BatchNormalization())\n    m.add(tf.keras.layers.LeakyReLU())\n\n    \"\"\"\n    m.add(tf.keras.layers.Conv2D(\n        64, (5, 5),\n        strides=(3, 3),\n        padding=\"valid\"\n    ))\n    m.add(tf.keras.layers.BatchNormalization())\n    m.add(tf.keras.layers.LeakyReLU())\n    \"\"\"\n    m.add(tf.keras.layers.Conv2D(\n        128, (4, 4),\n        strides=(2, 2),\n        padding=\"valid\"\n    ))\n    m.add(tf.keras.layers.BatchNormalization())\n    m.add(tf.keras.layers.LeakyReLU())\n    m.add(tf.keras.layers.Flatten())\n    m.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n    \n    return m",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ffc3874bb271fc27e6b4f899341dd506bda19e0d"
      },
      "cell_type": "code",
      "source": "generator = create_generator()\ndiscriminator = create_discriminator()\ngen_optimizer = tf.keras.optimizers.Adam(1e-4)\ndisc_optimizer = tf.keras.optimizers.Adam(1e-4)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "688a78cb3fcf3220a49545e6109464dd11d66a4b"
      },
      "cell_type": "code",
      "source": "@tf.function\ndef train_step(image):\n    noise = tf.random.normal((BATCH_SIZE, 100))\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        fake_image = generator(noise, training=True)\n        fake_output = discriminator(fake_image, training=True)\n        real_output = discriminator(image, training=True)\n        generator_loss = tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(fake_output), fake_output)\n        discriminator_loss = tf.keras.losses.BinaryCrossentropy()(tf.ones_like(fake_output), fake_output) + \\\n            tf.keras.losses.BinaryCrossentropy()(tf.zeros_like(real_output), real_output)\n            \n    gen_gradients = gen_tape.gradient(generator_loss, generator.trainable_variables)\n    disc_gradients = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n\n    gen_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n    disc_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n\n    return generator_loss, discriminator_loss\n        ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f632900bddf6dd2e7fdbde71bceadec0f5804c3"
      },
      "cell_type": "code",
      "source": "from matplotlib import pyplot as plt\ndef generate():\n    noise = tf.random.normal((1, 100))\n    return generator(noise, training=False)\n\ndef display_fake():\n    fake = generate()\n    plt.imshow(tf.reshape(fake, (28, 28)) * 127.5 + 127.5, cmap=\"gray\")",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7490c31eed7268bfd84b7016a9d85f4714575cbb"
      },
      "cell_type": "code",
      "source": "import os\n\ncheckpoint_dir = './checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(\n    gen_optimizer=gen_optimizer,\n    disc_optimizer=disc_optimizer,\n    generator=generator,\n    discriminator=discriminator\n)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e3c89d1e9698f1ee93448fb389ee1e67e660010"
      },
      "cell_type": "code",
      "source": "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f39824625c0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1265cffc885512f66e0bd8a12a515e2de96fe938"
      },
      "cell_type": "code",
      "source": "EPOCHS = 23\n\nfor i in range(EPOCHS):\n    for data in mnist_train:\n        image = data['image']\n        gen_loss, disc_loss = train_step(image)\n        #print(\"generator_loss: {} discriminator_loss: {}\".format(gen_loss, disc_loss))\n    print(\"generator_loss: {} discriminator_loss: {}\".format(gen_loss, disc_loss))  \n    display_fake()\n    checkpoint.save(file_prefix=checkpoint_prefix)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "W0317 03:39:07.741482 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f398239a548> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.748164 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f39823d8908> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.751422 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f39823d88b8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.754816 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f3982399ef8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.758040 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f3982399e08> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.761588 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f3982399cc8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.764662 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f398236de58> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.769188 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f3982390c78> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.773472 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f3982390958> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.778269 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f3982390598> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.781516 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f39823ef1d8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nW0317 03:39:07.786235 139886596937088 tf_logging.py:161] Entity <method-wrapper '__call__' of weakref object at 0x7f39823ef8b8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "WARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f398239a548> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f39823d8908> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f39823d88b8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f3982399ef8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f3982399e08> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f3982399cc8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f398236de58> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f3982390c78> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f3982390958> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f3982390598> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f39823ef1d8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\nWARNING: Entity <method-wrapper '__call__' of weakref object at 0x7f39823ef8b8> could not be transformed and will be staged without change. Error details can be found in the logs when running with the env variable AUTOGRAPH_VERBOSITY >= 1. Please report this to the AutoGraph team. Cause: Object conversion is not yet supported. If you are trying to convert code that uses an existing object, try including the creation of that object in the conversion. For example, instead of converting the method of a class, try converting the entire class instead. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/README.md#using-the-functional-api for more information.\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "generator_loss: 3.0720529556274414 discriminator_loss: 0.08591993153095245\ngenerator_loss: 3.3419108390808105 discriminator_loss: 0.08591771870851517\ngenerator_loss: 4.389967441558838 discriminator_loss: 0.08036617189645767\ngenerator_loss: 3.094813346862793 discriminator_loss: 0.09094463288784027\ngenerator_loss: 3.629865884780884 discriminator_loss: 0.12839756906032562\ngenerator_loss: 4.516965389251709 discriminator_loss: 0.08106769621372223\ngenerator_loss: 4.424652099609375 discriminator_loss: 0.09475690126419067\ngenerator_loss: 3.060769557952881 discriminator_loss: 0.12013158202171326\ngenerator_loss: 2.951828718185425 discriminator_loss: 0.12635184824466705\ngenerator_loss: 2.5360846519470215 discriminator_loss: 0.18269100785255432\ngenerator_loss: 3.6133389472961426 discriminator_loss: 0.13550858199596405\ngenerator_loss: 4.480701446533203 discriminator_loss: 0.2968885898590088\ngenerator_loss: 3.936915397644043 discriminator_loss: 0.172279492020607\ngenerator_loss: 3.0987377166748047 discriminator_loss: 0.1627626121044159\ngenerator_loss: 2.773313045501709 discriminator_loss: 0.14574605226516724\ngenerator_loss: 3.1598479747772217 discriminator_loss: 0.2064705491065979\ngenerator_loss: 3.0784249305725098 discriminator_loss: 0.22538526356220245\ngenerator_loss: 2.256478786468506 discriminator_loss: 0.25251486897468567\ngenerator_loss: 3.396481990814209 discriminator_loss: 0.215371236205101\ngenerator_loss: 3.3803491592407227 discriminator_loss: 0.17101240158081055\ngenerator_loss: 2.4669950008392334 discriminator_loss: 0.2781068980693817\ngenerator_loss: 1.3743228912353516 discriminator_loss: 0.45303842425346375\ngenerator_loss: 1.8956859111785889 discriminator_loss: 0.33128097653388977\n",
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b925052467a4852fe87305f3743da7c86dfd445f",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "display_fake()",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e336b4535469f7c072d89ec2465c6e78cf058f87"
      },
      "cell_type": "code",
      "source": "!cd checkpoints && \\\n    git config --global user.email \"michael_liu2@yahoo.com\" && \\\n    git config --global user.name \"Michael Liu\" && \\\n    git add -A && \\\n    git commit -m 'First commit' && \\\n    git push -f origin master;",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[master 9380115] First commit\n 47 files changed, 691030 insertions(+), 2 deletions(-)\n create mode 100644 ckpt-28.data-00000-of-00001\n create mode 100644 ckpt-28.index\n create mode 100644 ckpt-29.data-00000-of-00001\n create mode 100644 ckpt-29.index\n create mode 100644 ckpt-30.data-00000-of-00001\n create mode 100644 ckpt-30.index\n create mode 100644 ckpt-31.data-00000-of-00001\n create mode 100644 ckpt-31.index\n create mode 100644 ckpt-32.data-00000-of-00001\n create mode 100644 ckpt-32.index\n create mode 100644 ckpt-33.data-00000-of-00001\n create mode 100644 ckpt-33.index\n create mode 100644 ckpt-34.data-00000-of-00001\n create mode 100644 ckpt-34.index\n create mode 100644 ckpt-35.data-00000-of-00001\n create mode 100644 ckpt-35.index\n create mode 100644 ckpt-36.data-00000-of-00001\n create mode 100644 ckpt-36.index\n create mode 100644 ckpt-37.data-00000-of-00001\n create mode 100644 ckpt-37.index\n create mode 100644 ckpt-38.data-00000-of-00001\n create mode 100644 ckpt-38.index\n create mode 100644 ckpt-39.data-00000-of-00001\n create mode 100644 ckpt-39.index\n create mode 100644 ckpt-40.data-00000-of-00001\n create mode 100644 ckpt-40.index\n create mode 100644 ckpt-41.data-00000-of-00001\n create mode 100644 ckpt-41.index\n create mode 100644 ckpt-42.data-00000-of-00001\n create mode 100644 ckpt-42.index\n create mode 100644 ckpt-43.data-00000-of-00001\n create mode 100644 ckpt-43.index\n create mode 100644 ckpt-44.data-00000-of-00001\n create mode 100644 ckpt-44.index\n create mode 100644 ckpt-45.data-00000-of-00001\n create mode 100644 ckpt-45.index\n create mode 100644 ckpt-46.data-00000-of-00001\n create mode 100644 ckpt-46.index\n create mode 100644 ckpt-47.data-00000-of-00001\n create mode 100644 ckpt-47.index\n create mode 100644 ckpt-48.data-00000-of-00001\n create mode 100644 ckpt-48.index\n create mode 100644 ckpt-49.data-00000-of-00001\n create mode 100644 ckpt-49.index\n create mode 100644 ckpt-50.data-00000-of-00001\n create mode 100644 ckpt-50.index\nCounting objects: 49, done.\nDelta compression using up to 2 threads.\nCompressing objects: 100% (49/49), done.\nWriting objects: 100% (49/49), 179.34 MiB | 12.34 MiB/s, done.\nTotal 49 (delta 23), reused 0 (delta 0)\nTo https://bitbucket.org/furiousavocados19/dcgan-mnist-models.git\n   3d137fe..9380115  master -> master\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "531d89d6b2f412da0571a85d9cad7fb6bbf5f38d"
      },
      "cell_type": "code",
      "source": "!cd checkpoints && \\\n    git init && \\\n    git remote add origin https://furiousavocados19:password1234@bitbucket.org/furiousavocados19/dcgan-mnist-models.git && \\\n    git config --global user.email \"michael_liu2@yahoo.com\" && \\\n    git config --global user.name \"Michael Liu\" && \\\n    git add -A && \\\n    git commit -m 'First commit' && \\\n    git push -f origin master;",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-37-89677fd5ad58>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-89677fd5ad58>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    git config --global user.email \"michael_liu2@yahoo.com\" && git config --global user.name \"Michael Liu\" && git add -A && git commit -m \"First commit\" && git push -f origin master;\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "371f6e6c54eac2e81ca442ee076974e0e123e8b1"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}